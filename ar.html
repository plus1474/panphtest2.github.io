<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>ARカメラ</title>
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
    <style>
        body { margin: 0; overflow: hidden; }
        
        /* シャッターボタンのスタイル */
        .ui-container {
            position: fixed;
            bottom: 30px;
            left: 0;
            width: 100%;
            display: flex;
            justify-content: center;
            z-index: 20;
            pointer-events: none;
        }

        #snap-button {
            width: 70px;
            height: 70px;
            border-radius: 50%;
            background-color: rgba(255, 255, 255, 0.4);
            border: 4px solid #fff;
            outline: none;
            cursor: pointer;
            pointer-events: auto;
            transition: transform 0.1s;
        }

        #snap-button:active {
            background-color: #fff;
            transform: scale(0.9);
        }
    </style>
</head>
<body>
    <div class="ui-container">
        <button id="snap-button"></button>
    </div>

    <a-scene 
        embedded 
        arjs='sourceType: webcam; videoTextureParameters: { facingMode: environment, maxResolution: { width: 1170, height: 2572 } };'
        renderer="preserveDrawingBuffer: true;">
        
        <a-assets>
            <a-asset-item id="blender-model" src="AR_test.glb"></a-asset-item>
        </a-assets>

        <a-marker type="pattern" url="pattern-marker.patt">
            <a-entity
                gltf-model="#blender-model"
                position="0 0 0" 
                rotation="0 0 0" 
                scale="1 1 1">
            </a-entity>
        </a-marker>
        
        <a-entity camera></a-entity>
    </a-scene>

    <script>
        document.getElementById("snap-button").addEventListener("click", function() {
            const scene = document.querySelector("a-scene");
            const video = document.querySelector("video");
            
            // 1. 合成用のキャンバスを作成
            const mergeCanvas = document.createElement("canvas");
            // ★ここを変更：キャンバスサイズを現在のウィンドウ（画面）サイズに設定
            mergeCanvas.width = window.innerWidth;
            mergeCanvas.height = window.innerHeight;
            const ctx = mergeCanvas.getContext("2d");
    
            // 2. A-Frameのキャンバスを取得
            const aCanvas = scene.components.screenshot.getCanvas("perspective");
            
            // 3. 背景（カメラ映像）を描画
            if (video) {
                // ビデオ映像をキャンバスサイズに合わせて描画
                // （画面アスペクト比によっては多少歪む可能性がありますが、まずはこれで試します）
                ctx.drawImage(video, 0, 0, mergeCanvas.width, mergeCanvas.height);
            }
    
            // 4. 前景（3Dモデル）を描画
            // ★ここを変更：A-Frameのキャンバスを、合成キャンバスのサイズに合わせて描画（引き伸ばし）
            // drawImage(元画像, 元の切り取りX, 元の切り取りY, 元の幅, 元の高さ, 描画先X, 描画先Y, 描画先幅, 描画先高さ)
            ctx.drawImage(
                aCanvas, 
                0, 0, aCanvas.width, aCanvas.height, // 元画像の全領域を指定
                0, 0, mergeCanvas.width, mergeCanvas.height // 描画先の全領域を指定
            );
    
            // 5. ダウンロード処理（ここはそのまま）
            const link = document.createElement("a");
            const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
            link.download = `ar-photo-${timestamp}.png`;
            link.href = mergeCanvas.toDataURL("image/png");
            
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
        });
    </script>
</body>
</html>
